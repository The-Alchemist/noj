[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noj Documentation",
    "section": "",
    "text": "1 Preface\nNoj (scinojure) is an opinionated way to use the emerging Clojure data stack.\nIt collects a few of the main dependencies together with functions allowing to conveniently use them together.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "index.html#existing-chapters",
    "href": "index.html#existing-chapters",
    "title": "Noj Documentation",
    "section": "1.1 Existing chapters",
    "text": "1.1 Existing chapters\n\ndatasets\nimage\npython\nstats\nvisualization\nprepare_for_ml",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "index.html#wishlist",
    "href": "index.html#wishlist",
    "title": "Noj Documentation",
    "section": "1.2 Wishlist",
    "text": "1.2 Wishlist\n\na subset of ggplot2 ported to Clojure\n\n\n\n\n\nsource: notebooks/index.clj",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "2  Datasets",
    "section": "",
    "text": "(ns datasets\n  (:require [scicloj.noj.v1.datasets :as datasets]))\n\nNoj includes a few toy datasets for basic exploartions and tutorials. mtcars.csv and iris.csv were generated in R from Base R’s corresponding` datasets.\ndiamonds.csv was generated in R from R’s ggplot2 corresponding` datasets.\n\ndatasets/iris\n\n_unnamed [150 5]:\n\n\n\n\n\n\n\n\n\n\n:sepal-length\n:sepal-width\n:petal-length\n:petal-width\n:species\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n4.9\n3.1\n1.5\n0.1\nsetosa\n\n\n…\n…\n…\n…\n…\n\n\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\ndatasets/mtcars\n\n_unnamed [32 12]:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:name\n:mpg\n:cyl\n:disp\n:hp\n:drat\n:wt\n:qsec\n:vs\n:am\n:gear\n:carb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\ndatasets/diamonds\n\n_unnamed [53940 10]:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:carat\n:cut\n:color\n:clarity\n:depth\n:table\n:price\n:x\n:y\n:z\n\n\n\n\n0.23\nIdeal\nE\nSI2\n61.5\n55.0\n326\n3.95\n3.98\n2.43\n\n\n0.21\nPremium\nE\nSI1\n59.8\n61.0\n326\n3.89\n3.84\n2.31\n\n\n0.23\nGood\nE\nVS1\n56.9\n65.0\n327\n4.05\n4.07\n2.31\n\n\n0.29\nPremium\nI\nVS2\n62.4\n58.0\n334\n4.20\n4.23\n2.63\n\n\n0.31\nGood\nJ\nSI2\n63.3\n58.0\n335\n4.34\n4.35\n2.75\n\n\n0.24\nVery Good\nJ\nVVS2\n62.8\n57.0\n336\n3.94\n3.96\n2.48\n\n\n0.24\nVery Good\nI\nVVS1\n62.3\n57.0\n336\n3.95\n3.98\n2.47\n\n\n0.26\nVery Good\nH\nSI1\n61.9\n55.0\n337\n4.07\n4.11\n2.53\n\n\n0.22\nFair\nE\nVS2\n65.1\n61.0\n337\n3.87\n3.78\n2.49\n\n\n0.23\nVery Good\nH\nVS1\n59.4\n61.0\n338\n4.00\n4.05\n2.39\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n0.71\nIdeal\nG\nVS1\n61.4\n56.0\n2756\n5.76\n5.73\n3.53\n\n\n0.71\nPremium\nE\nSI1\n60.5\n55.0\n2756\n5.79\n5.74\n3.49\n\n\n0.71\nPremium\nF\nSI1\n59.8\n62.0\n2756\n5.74\n5.73\n3.43\n\n\n0.70\nVery Good\nE\nVS2\n60.5\n59.0\n2757\n5.71\n5.76\n3.47\n\n\n0.70\nVery Good\nE\nVS2\n61.2\n59.0\n2757\n5.69\n5.72\n3.49\n\n\n0.72\nPremium\nD\nSI1\n62.7\n59.0\n2757\n5.69\n5.73\n3.58\n\n\n0.72\nIdeal\nD\nSI1\n60.8\n57.0\n2757\n5.75\n5.76\n3.50\n\n\n0.72\nGood\nD\nSI1\n63.1\n55.0\n2757\n5.69\n5.75\n3.61\n\n\n0.70\nVery Good\nD\nSI1\n62.8\n60.0\n2757\n5.66\n5.68\n3.56\n\n\n0.86\nPremium\nH\nSI2\n61.0\n58.0\n2757\n6.15\n6.12\n3.74\n\n\n0.75\nIdeal\nD\nSI2\n62.2\n55.0\n2757\n5.83\n5.87\n3.64\n\n\n\n\n\n\n\nsource: notebooks/datasets.clj",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "image.html",
    "href": "image.html",
    "title": "3  Turning tensors into images",
    "section": "",
    "text": "(ns image\n  (:require [tech.v3.tensor :as tensor]\n            [tech.v3.datatype.functional :as fun]\n            [scicloj.noj.v1.vis.image :as vis.image]))\n\nThe vis.image/tensor-&gt;image function can help turning dtype-next’s tensors into Java BufferedImage objects.\nEventually, this function may find itself in dtype-next itself, see Issue #92 there.\nYou may see this function in action in the Clay & Noj demo: image processing at the Clojure Data Scrapbook and in the related video.\n\n(-&gt; (for [i (range 100)]\n      (range 100))\n    tensor/ensure-tensor\n    (fun/* 400)\n    (vis.image/tensor-&gt;image :ushort-gray))\n\n\n\n\n\n\n\n\nsource: notebooks/image.clj",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Turning tensors into images</span>"
    ]
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "4  Python",
    "section": "",
    "text": "4.1 Using Python visualizations\nNoj offers methods to include Python plots in Kindly visualizations: the vis.python/with-pyplot macro and the vis.python/pyplot function. They are based on the Parens for Pyplot blog post at Squid’s blog.\nhttps://seaborn.pydata.org/tutorial/introduction\nArviZ",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "python.html#using-python-visualizations",
    "href": "python.html#using-python-visualizations",
    "title": "4  Python",
    "section": "",
    "text": "(require-python '[numpy :as np]\n                '[numpy.random :as np.random]\n                'matplotlib.pyplot\n                '[seaborn :as sns]\n                'json\n                '[arviz :as az])\n\n\n:ok\n\n\n(def sine-data\n  (-&gt; {:x (range 0 (* 3 np/pi) 0.1)}\n      tc/dataset\n      (tc/add-column :y #(fun/sin (:x %)))))\n\n\n(vis.python/with-pyplot\n  (matplotlib.pyplot/plot\n   (:x sine-data)\n   (:y sine-data)))\n\n\n\n\n\n\n\n(vis.python/pyplot\n #(matplotlib.pyplot/plot\n   (:x sine-data)\n   (:y sine-data)))\n\n\n\n\n\n\n\n\n(let [tips (sns/load_dataset \"tips\")]\n  (sns/set_theme)\n  (vis.python/pyplot\n   #(sns/relplot :data tips\n                 :x \"total_bill\"\n                 :y \"tip\"\n                 :col \"time\"\n                 :hue \"smoker\"\n                 :style \"smoker\"\n                 :size \"size\")))\n\n\n\n\n\n\n\n\n(let [size [10 50]\n      data {:normal (apply np.random/randn size)\n            :gumbel (np.random/gumbel :size size)\n            :student_t (np.random/standard_t :df 6\n                                             :size size)\n            :exponential (np.random/exponential :size size)}]\n  (vis.python/pyplot\n   #(az/plot_forest data)))\n\n\n\n\n\n\n\n:bye\n\n\n:bye\n\n\n\n\n\nsource: notebooks/python.clj",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "stats.html",
    "href": "stats.html",
    "title": "5  Statistics",
    "section": "",
    "text": "5.1 Correlation matrices\nThe stats/calc-correlations-matrix function commputes the correlation matrix of selected columns of a given dataset, organizing the resulting data as a dataset.\n_unnamed [16 3]:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "stats.html#correlation-matrices",
    "href": "stats.html#correlation-matrices",
    "title": "5  Statistics",
    "section": "",
    "text": "(-&gt; datasets/iris\n    (stats/calc-correlations-matrix\n     [:sepal-length :sepal-width :petal-length :petal-width]))\n\n\n\n\n\n:col-1\n:col-2\n:corr\n\n\n\n\n:sepal-length\n:sepal-length\n1.00000000\n\n\n:sepal-length\n:sepal-width\n-0.11000000\n\n\n:sepal-length\n:petal-length\n0.87000000\n\n\n:sepal-length\n:petal-width\n0.81000000\n\n\n:sepal-width\n:sepal-length\n-0.11000000\n\n\n:sepal-width\n:sepal-width\n1.00000000\n\n\n:sepal-width\n:petal-length\n-0.41999999\n\n\n:sepal-width\n:petal-width\n-0.36000001\n\n\n:petal-length\n:sepal-length\n0.87000000\n\n\n:petal-length\n:sepal-width\n-0.41999999\n\n\n:petal-length\n:petal-length\n1.00000000\n\n\n:petal-length\n:petal-width\n0.95999998\n\n\n:petal-width\n:sepal-length\n0.81000000\n\n\n:petal-width\n:sepal-width\n-0.36000001\n\n\n:petal-width\n:petal-length\n0.95999998\n\n\n:petal-width\n:petal-width\n1.00000000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "stats.html#multivariate-regression",
    "href": "stats.html#multivariate-regression",
    "title": "5  Statistics",
    "section": "5.2 Multivariate regression",
    "text": "5.2 Multivariate regression\nThe stats/regression-model function computes a regressiom model (using scicloj.ml) and adds some relevant information such as the R^2 measure.\n\n(-&gt; datasets/iris\n    (stats/regression-model\n     :sepal-length\n     [:sepal-width :petal-length :petal-width]\n     {:model-type :smile.regression/elastic-net})\n    (dissoc :model-data))\n\n\n{:feature-columns [:sepal-width :petal-length :petal-width],\n :target-columns [:sepal-length],\n :explained\n #object[malli.core$_instrument$fn__47898 0xdc4d1ca \"malli.core$_instrument$fn__47898@dc4d1ca\"],\n :R2 0.8582120394597336,\n :id #uuid \"9aa7b239-ddd5-4f87-8248-460ec22f1f10\",\n :predictions #tech.v3.dataset.column&lt;float64&gt;[150]\n:sepal-length\n[5.022, 4.724, 4.775, 4.851, 5.081, 5.360, 4.911, 5.030, 4.664, 4.903, 5.209, 5.098, 4.775, 4.572, 5.184, 5.522, 5.089, 4.970, 5.352, 5.217...],\n :predict\n #object[scicloj.noj.v1.stats$regression_model$predict__52114 0x332759bb \"scicloj.noj.v1.stats$regression_model$predict__52114@332759bb\"],\n :options {:model-type :smile.regression/elastic-net}}\n\n\n(-&gt; datasets/iris\n    (stats/regression-model\n     :sepal-length\n     [:sepal-width :petal-length :petal-width]\n     {:model-type :smile.regression/ordinary-least-square})\n    (dissoc :model-data))\n\n\n{:feature-columns [:sepal-width :petal-length :petal-width],\n :target-columns [:sepal-length],\n :explained\n #object[malli.core$_instrument$fn__47898 0xdc4d1ca \"malli.core$_instrument$fn__47898@dc4d1ca\"],\n :R2 0.8586117200664085,\n :id #uuid \"db3b1f6b-6e40-43cd-8b92-0e07d6f16429\",\n :predictions #tech.v3.dataset.column&lt;float64&gt;[150]\n:sepal-length\n[5.015, 4.690, 4.749, 4.826, 5.080, 5.377, 4.895, 5.021, 4.625, 4.882, 5.216, 5.092, 4.746, 4.533, 5.199, 5.561, 5.094, 4.960, 5.368, 5.226...],\n :predict\n #object[scicloj.noj.v1.stats$regression_model$predict__52114 0x657bb921 \"scicloj.noj.v1.stats$regression_model$predict__52114@657bb921\"],\n :options {:model-type :smile.regression/ordinary-least-square}}\n\nThe stats/linear-regression-model convenience function uses specifically the :smile.regression/ordinary-least-square model type.\n\n(-&gt; datasets/iris\n    (stats/linear-regression-model\n     :sepal-length\n     [:sepal-width :petal-length :petal-width])\n    (dissoc :model-data))\n\n\n{:feature-columns [:sepal-width :petal-length :petal-width],\n :target-columns [:sepal-length],\n :explained\n #object[malli.core$_instrument$fn__47898 0xdc4d1ca \"malli.core$_instrument$fn__47898@dc4d1ca\"],\n :R2 0.8586117200664085,\n :id #uuid \"92ea3d77-a5b8-444e-8050-6dd8bd3a0e1b\",\n :predictions #tech.v3.dataset.column&lt;float64&gt;[150]\n:sepal-length\n[5.015, 4.690, 4.749, 4.826, 5.080, 5.377, 4.895, 5.021, 4.625, 4.882, 5.216, 5.092, 4.746, 4.533, 5.199, 5.561, 5.094, 4.960, 5.368, 5.226...],\n :predict\n #object[scicloj.noj.v1.stats$regression_model$predict__52114 0x3c2fe97b \"scicloj.noj.v1.stats$regression_model$predict__52114@3c2fe97b\"],\n :options {:model-type :smile.regression/ordinary-least-square}}",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "stats.html#adding-regression-predictions-to-a-dataset",
    "href": "stats.html#adding-regression-predictions-to-a-dataset",
    "title": "5  Statistics",
    "section": "5.3 Adding regression predictions to a dataset",
    "text": "5.3 Adding regression predictions to a dataset\nThe stats/add-predictions function models a target column using feature columns, adds a new prediction column with the model predictions.\n\n(-&gt; datasets/iris\n    (stats/add-predictions\n     :sepal-length\n     [:sepal-width :petal-length :petal-width]\n     {:model-type :smile.regression/ordinary-least-square}))\n\n_unnamed [150 6]:\n\n\n\n\n\n\n\n\n\n\n\n:sepal-length\n:sepal-width\n:petal-length\n:petal-width\n:species\n:sepal-length-prediction\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n5.01541576\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n4.68999718\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n4.74925142\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n4.82599409\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n5.08049948\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n5.37719368\n\n\n4.6\n3.4\n1.4\n0.3\nsetosa\n4.89468378\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n5.02124524\n\n\n4.4\n2.9\n1.4\n0.2\nsetosa\n4.62491347\n\n\n4.9\n3.1\n1.5\n0.1\nsetosa\n4.88164236\n\n\n…\n…\n…\n…\n…\n…\n\n\n6.9\n3.1\n5.4\n2.1\nvirginica\n6.53429168\n\n\n6.7\n3.1\n5.6\n2.4\nvirginica\n6.50917327\n\n\n6.9\n3.1\n5.1\n2.3\nvirginica\n6.21025556\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n6.17251376\n\n\n6.8\n3.2\n5.9\n2.3\nvirginica\n6.84264484\n\n\n6.7\n3.3\n5.7\n2.5\nvirginica\n6.65460564\n\n\n6.7\n3.0\n5.2\n2.3\nvirginica\n6.21608504\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n5.97143313\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n6.38302984\n\n\n6.2\n3.4\n5.4\n2.3\nvirginica\n6.61824630\n\n\n5.9\n3.0\n5.1\n1.8\nvirginica\n6.42341317\n\n\n\nIt attaches the model’s information to the metadata of that new column.\n\n(-&gt; datasets/iris\n    (stats/add-predictions\n     :sepal-length\n     [:sepal-width :petal-length :petal-width]\n     {:model-type :smile.regression/ordinary-least-square})\n    :sepal-length-prediction\n    meta\n    (update :model\n            dissoc :model-data :predict :predictions))\n\n\n{:name :sepal-length-prediction,\n :datatype :float64,\n :n-elems 150,\n :column-type :prediction,\n :model\n {:feature-columns [:sepal-width :petal-length :petal-width],\n  :target-columns [:sepal-length],\n  :explained\n  #object[malli.core$_instrument$fn__47898 0xdc4d1ca \"malli.core$_instrument$fn__47898@dc4d1ca\"],\n  :R2 0.8586117200664085,\n  :id #uuid \"54d8ffd2-59d0-46a5-a3f5-9d9add60cbe9\",\n  :options {:model-type :smile.regression/ordinary-least-square}}}",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "stats.html#histograms",
    "href": "stats.html#histograms",
    "title": "5  Statistics",
    "section": "5.4 Histograms",
    "text": "5.4 Histograms\nThe stats/histogram function computes the necessary data to plot a histogram.\n\n(-&gt; (repeatedly 99 rand)\n    (stats/histogram {:bin-count 5}))\n\n_unnamed [5 3]:\n\n\n\n:count\n:left\n:right\n\n\n\n\n29\n0.00553885\n0.20435082\n\n\n16\n0.20435082\n0.40316279\n\n\n25\n0.40316279\n0.60197475\n\n\n15\n0.60197475\n0.80078672\n\n\n14\n0.80078672\n0.99959868\n\n\n\n\n\n\n\nsource: notebooks/stats.clj",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics</span>"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "6  Visualization",
    "section": "",
    "text": "6.1 Visualizing datases with Hanami\nNoj offers a few convenience functions to make Hanami plotting work smoothly with Tablecloth and Kindly.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#visualizing-datases-with-hanami",
    "href": "visualization.html#visualizing-datases-with-hanami",
    "title": "6  Visualization",
    "section": "",
    "text": "(def random-walk\n  (let [n 20]\n    (-&gt; {:x (range n)\n         :y (-&gt;&gt; (repeatedly n #(- (rand) 0.5))\n                 (reductions +))}\n        tc/dataset)))\n\n\n6.1.1 A simple plot\nWe can plot a Tablecloth datasete using a Hanami template:\n\n(-&gt; random-walk\n    (hanami/plot ht/point-chart\n                 {:MSIZE 200}))\n\n\n\n\n\n\nLet us look inside the resulting vega-lite space. We can see the dataset is included as CSV:\n\n(-&gt; random-walk\n    (hanami/plot ht/point-chart\n                 {:MSIZE 200})\n    kind/pprint)\n\n\n{:encoding\n {:y {:field \"y\", :type \"quantitative\"},\n  :x {:field \"x\", :type \"quantitative\"}},\n :mark {:type \"circle\", :size 200, :tooltip true},\n :width 400,\n :background \"floralwhite\",\n :height 300,\n :data\n {:values\n  \"x,y\\n0,-0.09553378290097758\\n1,-0.3777436246632112\\n2,-0.06630039987979008\\n3,-0.44735860549027395\\n4,-0.5200839293798569\\n5,-0.8566429901792593\\n6,-0.41708419297252086\\n7,-0.863901382851194\\n8,-0.40349775589971415\\n9,-0.39581487872180887\\n10,-0.243293921410361\\n11,-0.7217824969046849\\n12,-1.1657842659593967\\n13,-0.769214913731935\\n14,-0.6834264993938615\\n15,-0.47612944334472074\\n16,-0.46160796926827263\\n17,-0.345556012818633\\n18,0.027989356549508404\\n19,0.26725445925376967\\n\",\n  :format {:type \"csv\"}}}\n\n\n\n6.1.2 Additional Hanami templates\nThe scicloj.noj.v1.vis.hanami.templates namespace add Hanami templates to Hanami’s own collection.\n\n(-&gt; datasets/mtcars\n    (hanami/plot vht/boxplot-chart\n                 {:X :gear\n                  :XTYPE :nominal\n                  :Y :mpg}))\n\n\n\n\n\n\n\n(-&gt; datasets/iris\n    (hanami/plot vht/rule-chart\n                 {:X :sepal-width\n                  :Y :sepal-length\n                  :X2 :petal-width\n                  :Y2 :petal-length\n                  :OPACITY 0.2\n                  :SIZE 3\n                  :COLOR \"species\"}))\n\n\n\n\n\n\n\n\n6.1.3 Grouped datasets\nGrouped datasets are handled automatically with a table view.\n\n(-&gt; datasets/iris\n    (tc/group-by [:species])\n    (hanami/plot vht/rule-chart\n                 {:X :sepal-width\n                  :Y :sepal-length\n                  :X2 :petal-width\n                  :Y2 :petal-length\n                  :OPACITY 0.2\n                  :SIZE 3}))\n\n\n\n\n\n\nspecies\n\n\nplot\n\n\n\n\n\n\n\n\nsetosa\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nversicolor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvirginica\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.4 Layers\n\n(-&gt; random-walk\n    (hanami/layers\n     {:TITLE \"points and a line\"}\n     [(hanami/plot nil\n                   ht/point-chart\n                   {:MSIZE 400})\n      (hanami/plot nil\n                   ht/line-chart\n                   {:MSIZE 4\n                    :MCOLOR \"brown\"})]))\n\n\n\n\n\n\nAlternatively:\n\n(-&gt; random-walk\n    (hanami/combined-plot\n     ht/layer-chart\n     {:TITLE \"points and a line\"}\n     :LAYER [[ht/point-chart\n              {:MSIZE 400}]\n             [ht/line-chart\n              {:MSIZE 4\n               :MCOLOR \"brown\"}]]))\n\n\n\n\n\n\n\n\n6.1.5 Concatenation\nVertical\n\n(-&gt; random-walk\n    (hanami/vconcat\n     {}\n     [(hanami/plot nil\n                   ht/point-chart\n                   {:MSIZE 400\n                    :HEIGHT 100\n                    :WIDTH 100})\n      (hanami/plot nil\n                   ht/line-chart\n                   {:MSIZE 4\n                    :MCOLOR \"brown\"\n                    :HEIGHT 100\n                    :WIDTH 100})]))\n\n\n\n\n\n\nAlternatively:\n\n(-&gt; random-walk\n    (hanami/combined-plot\n     ht/vconcat-chart\n     {:HEIGHT 100\n      :WIDTH 100}\n     :VCONCAT [[ht/point-chart\n                {:MSIZE 400}]\n               [ht/line-chart\n                {:MSIZE 4\n                 :MCOLOR \"brown\"}]]))\n\n\n\n\n\n\nHorizontal\n\n(-&gt; random-walk\n    (hanami/hconcat\n     {}\n     [(hanami/plot nil\n                       ht/point-chart\n                       {:MSIZE 400\n                        :HEIGHT 100\n                        :WIDTH 100})\n      (hanami/plot nil\n                       ht/line-chart\n                       {:MSIZE 4\n                        :MCOLOR \"brown\"\n                        :HEIGHT 100\n                        :WIDTH 100})]))\n\n\n\n\n\n\nAlternatively:\n\n(-&gt; random-walk\n    (hanami/combined-plot\n     ht/hconcat-chart\n     {:HEIGHT 100\n      :WIDTH 100}\n     :HCONCAT [[ht/point-chart\n                {:MSIZE 400}]\n               [ht/line-chart\n                {:MSIZE 4\n                 :MCOLOR \"brown\"}]]))\n\n\n\n\n\n\n\n\n6.1.6 Linear regression\n\n(-&gt; datasets/mtcars\n    (stats/add-predictions :mpg [:wt]\n                           {:model-type :smile.regression/ordinary-least-square})\n    (hanami/combined-plot\n     ht/layer-chart\n     {:X :wt\n      :MSIZE 200\n      :HEIGHT 200}\n     :LAYER [[ht/point-chart\n              {:Y :mpg\n               :WIDTH 200}]\n             [ht/line-chart\n              {:Y :mpg-prediction\n               :MSIZE 5\n               :MCOLOR \"purple\"\n               :YTITLE :mpg}]]))\n\n\n\n\n\n\nAlternatively:\n\n(-&gt; datasets/mtcars\n    (hanami/linear-regression-plot\n     :mpg :wt\n     {:HEIGHT 200\n      :WIDTH 200\n      :point-options {:MSIZE 200}\n      :line-options {:MSIZE 5\n                     :MCOLOR \"purple\"}}))\n\n\n\n\n\n\nAnd in a grouped dataset case:\n\n(-&gt; datasets/mtcars\n    (tc/group-by [:gear])\n    (hanami/linear-regression-plot\n     :mpg :wt\n     {:HEIGHT 200\n      :WIDTH 200\n      :point-options {:MSIZE 200}\n      :line-options {:MSIZE 5\n                     :MCOLOR \"purple\"}}))\n\n\n\n\n\n\ngear\n\n\nplot\n\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.7 Histogram\nA histogram groups values in bins, counts them, and creates a corresponding bar-chart.\nThe hanami/histogram functions does that behind the scenes, and generates a Vega-Lite spec using Hanami.\n\n(-&gt; datasets/iris\n    (hanami/histogram :sepal-width\n                      {:nbins 10}))\n\n\n\n\n\n\n\n(-&gt; datasets/iris\n    (hanami/histogram :sepal-width\n                      {:nbins 10})\n    kind/pprint)\n\n\n{:encoding\n {:y {:field :count, :type \"quantitative\"},\n  :x\n  {:scale {:zero false},\n   :field :left,\n   :type \"quantitative\",\n   :title :sepal-width},\n  :y2 {:field 0, :type \"quantitative\"},\n  :x2 {:scale {:zero false}, :field :right, :type \"quantitative\"}},\n :mark \"rect\",\n :width 400,\n :background \"floralwhite\",\n :height 300,\n :data\n {:values\n  \"count,left,right\\n4,2.0,2.24\\n7,2.24,2.48\\n22,2.48,2.72\\n24,2.72,2.96\\n37,2.96,3.2\\n31,3.2,3.4400000000000004\\n10,3.4400000000000004,3.6800000000000006\\n11,3.6800000000000006,3.9200000000000004\\n2,3.9200000000000004,4.16\\n2,4.16,4.4\\n\",\n  :format {:type \"csv\"}}}\n\nThe resulting spec can be customized further:\n\n(-&gt; datasets/iris\n    (hanami/histogram :sepal-width\n                      {:nbins 10})\n    ;; varying the resulting vega-lite spec:\n    (assoc :height 125\n           :width 175))\n\n\n\n\n\n\n\n\n6.1.8 Combining a few things together\nThe following is inspired by the example at Plotnine’s main page. Note how we add regression lines here. We take care of layout and colouring on our side, not using Vega-Lite for that.\n\n(let [pallete (-&gt;&gt; :accent\n                   color/palette\n                   (mapv color/format-hex))]\n  (-&gt; datasets/mtcars\n      (tc/group-by :gear {:result-type :as-map})\n      (-&gt;&gt; (sort-by key)\n           (map-indexed\n            (fn [i [group-name ds]]\n              (-&gt; ds\n                  (hanami/linear-regression-plot\n                   :mpg :wt\n                   {:TITLE (str \"grear=\" group-name)\n                    :X :wt\n                    :MCOLOR (pallete i)\n                    :HEIGHT 200\n                    :WIDTH 200\n                    :point-options {:MSIZE 200}\n                    :line-options {:MSIZE 5}}))))\n           (hanami/vconcat nil {}))))\n\n\n\n\n\n\nAlternatively, using a grouped dataset:\n\n(let [pallete (-&gt;&gt; :accent\n                   color/palette\n                   (mapv color/format-hex))]\n  (-&gt; datasets/mtcars\n      (tc/map-columns :color [:gear] #(-&gt; % (- 3) pallete))\n      (tc/group-by [:gear])\n      (hanami/linear-regression-plot\n       :mpg :wt\n       {:X :wt\n        :MCOLOR {:expr \"datum.color\"}\n        :HEIGHT 200\n        :WIDTH 200\n        :point-options {:MSIZE 200}\n        :line-options {:MSIZE 5}})\n      (tc/order-by [:gear])))\n\n\n\n\n\n\ngear\n\n\nplot\n\n\n\n\n\n\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA similar example with histograms:\n\n(let [pallete (-&gt;&gt; :accent\n                   color/palette\n                   (mapv color/format-hex))]\n  (-&gt; datasets/iris\n      (tc/group-by :species {:result-type :as-map})\n      (-&gt;&gt; (sort-by key)\n           (map-indexed\n            (fn [i [group-name ds]]\n              (-&gt; ds\n                  (hanami/histogram :sepal-width\n                                    {:nbins 10}))))\n           (hanami/vconcat nil {}))))\n\n\n\n\n\n\nScatterplots and regression lines again, this time using Vega-Lite for layout and coloring (using its “facet” option).\n\n(-&gt; datasets/mtcars\n    (tc/group-by [:gear])\n    (stats/add-predictions :mpg [:wt]\n                           {:model-type :smile.regression/ordinary-least-square})\n    (tc/ungroup)\n    (tc/select-columns [:gear :wt :mpg :mpg-prediction])\n    (hanami/combined-plot\n     ht/layer-chart\n     {}\n     :LAYER [[ht/point-chart\n              {:X :wt\n               :Y :mpg\n               :MSIZE 200\n               :COLOR \"gear\"\n               :HEIGHT 100\n               :WIDTH 200}]\n             [ht/line-chart\n              {:X :wt\n               :Y :mpg-prediction\n               :MSIZE 5\n               :COLOR \"gear\"\n               :YTITLE :mpg}]])\n    ((fn [spec]\n       {:facet {:row {:field \"gear\"}}\n        :spec (dissoc spec :data)\n        :data (:data spec)}))\n    kind/vega-lite)\n\n\n\n\n\n\n\n:bye\n\n\n:bye\n\n\n\n\n\nsource: notebooks/visualization.clj",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html",
    "href": "prepare_for_ml.html",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "",
    "text": "7.1 Categorical variables\nOne typical problem in machine learning is classification, so learning how to categorize data in different categories. Sometimes data in this format is as well called “qualitative data” or data having discrete values.\nThese categories are often expressed in Clojure as of being of type String or keyword\nIn dataset it is the Column which has specific support for categorical data.\nCreating a column out of categorical data looks like this:\nThis creates a “categorical” column, which is marked as such in the column metadata. Printing the var shows its “type” as being keyword\nand printing its metadata shows that it got marked as categorical\nThe column is therefore using its metadata to store important information, and it is important to get used to look at it for the case of debugging issues.\nThe same happens, when creating a dataset which is a seq of columns\n_unnamed [2 2]:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html#categorical-variables",
    "href": "prepare_for_ml.html#categorical-variables",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "",
    "text": "(require '[tech.v3.dataset.column :as col]\n         '[tech.v3.dataset :as ds])\n\n\n(def column-x (col/new-column  :x  [:a :b]))\n\n\n\ncolumn-x\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[2]\n:x\n[:a, :b]\n\n\n\n(meta column-x)\n\n\n{:categorical? true, :name :x, :datatype :keyword, :n-elems 2}\n\n\n\n\n(def categorical-ds\n  (ds/-&gt;dataset\n   {:x [:a :b] :y [\"c\" \"d\"]}))\n\n\ncategorical-ds\n\n\n\n\n\n:x\n:y\n\n\n\n\n:a\nc\n\n\n:b\nd\n\n\n\n\n(map\n meta\n (vals categorical-ds))\n\n\n({:categorical? true, :name :x, :datatype :keyword, :n-elems 2}\n {:categorical? true, :name :y, :datatype :string, :n-elems 2})\n\n\n7.1.1 Transform categorical variables to numerical space\nMost machine learning models can only work on numerical values, both for features and the target variable. So usually we need to transform categorical data into a numeric representation, so each category need to be converted to a number.\nThese numbers have often no meaning for the users, so often we need to convert back into String / keyword space later on.\nNamespace tech.v3.dataste.categorical has several functions to do so.\n\n\n7.1.2 Transform categorical column into a numerical column\n\n(require  '[tech.v3.dataset.categorical :as ds-cat])\n\nThese functions operate on a single column, but expect a dataset and a column name as input.\nWe use them to calculate a mapping from string/keyword to a numerical space (0 … x) like this\n\n(ds-cat/fit-categorical-map categorical-ds :x)\n\n\n{:lookup-table {:a 0, :b 1}, :src-column :x, :result-datatype :float64}\n\nThis maps the values in their order of occurrence in the column to 0 .. 1 This is a bit dangerous, as the mapping is decided by “row order”, which could change or be different on other subset of the data, like test/train splits\nSo it is preferred to be specified explicitly.\n\n(def x-mapping (ds-cat/fit-categorical-map categorical-ds :x [:a :b]))\n\n\nx-mapping\n\n\n{:lookup-table {:a 0, :b 1}, :src-column :x, :result-datatype :float64}\n\nNow we know for sure, that :a is mapped to 0 and :b is mapped to 1. Once we have a mapping, we can use it on new data and transform it into numerical values\n\n(def numerical-categorical-data\n  (ds-cat/transform-categorical-map\n   (ds/-&gt;dataset {:x [:a :b :a :b :b :b]})\n   x-mapping))\n\n\nnumerical-categorical-data\n\n_unnamed [6 1]:\n\n\n\n:x\n\n\n\n\n0.0\n\n\n1.0\n\n\n0.0\n\n\n1.0\n\n\n1.0\n\n\n1.0\n\n\n\nWe can revert it as well:\n\n(ds-cat/invert-categorical-map numerical-categorical-data x-mapping)\n\n_unnamed [6 1]:\n\n\n\n:x\n\n\n\n\n:a\n\n\n:b\n\n\n:a\n\n\n:b\n\n\n:b\n\n\n:b\n\n\n\nWe can as well ask about all mapping of a dataset:\n\n(ds-cat/dataset-&gt;categorical-maps numerical-categorical-data)\n\n\n({:lookup-table {:a 0, :b 1},\n  :src-column :x,\n  :result-datatype :float64})",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html#warning-categorical-maps-attached-to-a-column-change-semantic-value-of-the-column",
    "href": "prepare_for_ml.html#warning-categorical-maps-attached-to-a-column-change-semantic-value-of-the-column",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "7.2 Warning: Categorical maps attached to a column change semantic value of the Column",
    "text": "7.2 Warning: Categorical maps attached to a column change semantic value of the Column\nThe existence of categorical maps on a column, change the semantic value of the data. When categorical maps are different for two columns (for whatever reasons), it is not given that the column cell value like 0 means the same in both columns. Columns which have categorical maps should never be compared via clojure.core/= as this will ignore the categorical maps. (unless we are sure that the categorical maps in both are the same) They should be converted back to their original space and then compared. This is specially important for comparing prediction and true value in machine learning for metric calculations. See the following example to illustrate this.\n\n7.2.1 Incorrect comparisons\nIn the following the two columns are clearly different (the opposite even)\n\n(def ds-with-different-cat-maps\n  (-&gt;\n   (ds/-&gt;dataset {:x-1 [:a :b :a :b :b :b]\n                  :x-2 [:b :a :b :a :a :a]})\n   (ds/categorical-&gt;number [:x-1 :x-2])))\n\n\n(:x-1 ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-1\n[0, 1, 0, 1, 1, 1]\n\n\n(:x-2 ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-2\n[0, 1, 0, 1, 1, 1]\n\nBy using default categorical-&gt;number we get different categorical maps, having different :lookup-tables\n\n(meta (:x-1 ds-with-different-cat-maps))\n\n\n{:categorical? true,\n :name :x-1,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-1,\n  :result-datatype :float64}}\n\n\n(meta (:x-2 ds-with-different-cat-maps))\n\n\n{:categorical? true,\n :name :x-2,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:b 0, :a 1},\n  :src-column :x-2,\n  :result-datatype :float64}}\n\nso they are (wrongly) compared as equal\n\n(=\n (:x-1 ds-with-different-cat-maps)\n (:x-2 ds-with-different-cat-maps))\n\n\ntrue\n\n\n\n7.2.2 Correct comparison\nIn order to compare them correctly, we need to first revert the categorical mappings\n\n(def reverted-ds-with-different-cat-maps\n  (ds-cat/reverse-map-categorical-xforms ds-with-different-cat-maps))\n\n\n(:x-1 reverted-ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[6]\n:x-1\n[:a, :b, :a, :b, :b, :b]\n\n\n(:x-2 reverted-ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[6]\n:x-2\n[:b, :a, :b, :a, :a, :a]\n\nand now they compare correctly as :false\n\n(=\n (:x-1 reverted-ds-with-different-cat-maps)\n (:x-2 reverted-ds-with-different-cat-maps))\n\n\nfalse\n\nSo it should be as well avoided to transform mapped columns to other representations, which loose the mappings, like tensor or primitive arrays, or even sequences\n\n\n7.2.3 Use the same and fixed mapping\nThis issue can be avoided by specifying concretely the mapping to be useds, as being for exmaple {:a 0 :b 1}\n\n(def ds-with-same-cat-maps\n  (-&gt;\n   (ds/-&gt;dataset {:x-1 [:a :b :a :b :b :b]\n                  :x-2 [:b :a :b :a :a :a]})\n   (ds/categorical-&gt;number [:x-1 :x-2] [:a :b])))\n\nmapping spec can be either [:a :b] or [:a 0 :b 1]\n\n(:x-1 ds-with-same-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-1\n[0, 1, 0, 1, 1, 1]\n\n\n(:x-2 ds-with-same-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-2\n[1, 0, 1, 0, 0, 0]\n\nwe get same categorical maps\n\n(meta (:x-1 ds-with-same-cat-maps))\n\n\n{:categorical? true,\n :name :x-1,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-1,\n  :result-datatype :float64}}\n\n\n(meta (:x-2 ds-with-same-cat-maps))\n\n\n{:categorical? true,\n :name :x-2,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-2,\n  :result-datatype :float64}}\n\nso they are correctly compared as not equal\n\n(=\n (:x-1 ds-with-same-cat-maps)\n (:x-2 ds-with-same-cat-maps))\n\n\nfalse",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html#convert-several-columns-in-one-go",
    "href": "prepare_for_ml.html#convert-several-columns-in-one-go",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "7.3 Convert several columns in one go",
    "text": "7.3 Convert several columns in one go\nThe dataset namespace has as well a convenience function in which several columns can be choose for conversion.\n\n(ds/categorical-&gt;number categorical-ds [:x :y])\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n1.0\n\n\n1.0\n0.0\n\n\n\nThis works as well with filter function from namespace column-filters\n\n(require '[tech.v3.dataset.column-filters :as ds-cf])\n\nto convert all categorical columns, for example:\n\n(ds/categorical-&gt;number categorical-ds ds-cf/categorical)\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n1.0\n\n\n1.0\n0.0\n\n\n\n\n7.3.1 one-hot-encoding\nFor some models / use cases the categorical data need to be converted in the so called one-hot format. In this every column get multiplied by the number of categories , and then each one-hot column can only have 0 and 1 values.\n\n(def one-hot-map-x (ds-cat/fit-one-hot categorical-ds :x))\n\n\n(def one-hot-map-y (ds-cat/fit-one-hot categorical-ds :y))\n\n\none-hot-map-x\n\n\n{:one-hot-table {:a :x-a, :b :x-b},\n :src-column :x,\n :result-datatype :float64}\n\n\none-hot-map-y\n\n\n{:one-hot-table {\"d\" :y-d, \"c\" :y-c},\n :src-column :y,\n :result-datatype :float64}\n\n\ncategorical-ds\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n:a\nc\n\n\n:b\nd\n\n\n\nget transformed by\n\n(def one-hot-ds\n  (-&gt; categorical-ds\n      (ds-cat/transform-one-hot one-hot-map-x)\n      (ds-cat/transform-one-hot one-hot-map-y)))\n\ninto\n\none-hot-ds\n\n_unnamed [2 4]:\n\n\n\n:x-a\n:x-b\n:y-d\n:y-c\n\n\n\n\n1.0\n0.0\n0.0\n1.0\n\n\n0.0\n1.0\n1.0\n0.0\n\n\n\nThere are similar functions to convert this format back.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html#features-and-inference-target-in-a-dataset",
    "href": "prepare_for_ml.html#features-and-inference-target-in-a-dataset",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "7.4 Features and inference target in a dataset",
    "text": "7.4 Features and inference target in a dataset\nA dataset for supervised machine learning has always two groups of columns. They can either be the features or the inference targets. The goal of the learning is to find the relationship between the two groups and therefore be able to predict inference targets from features. Sometimes the features are called X and the targets y. When constructing a dataset\n\n(def ds\n  (ds/-&gt;dataset {:x-1 [0 1 0]\n                 :x-2 [1 0 1]\n                 :y [:a :a :b]}))\n\nwe need to mark explicitly which columns are features and which are targets in order to be able to use the dataset later for machine learning in metamorph.ml\nAs normally only one or a few columns are inference targets, we can simply mark those and the oder columns are regarded as features.\n\n(require  '[tech.v3.dataset.modelling :as ds-mod])\n\n\n(def modelled-ds\n  (-&gt; ds\n      (ds-mod/set-inference-target :y)))\n\n(works as well with a seq) This is marked as well in the column metadata.\n\n(-&gt; modelled-ds :y meta)\n\n\n{:categorical? true,\n :name :y,\n :datatype :keyword,\n :n-elems 3,\n :inference-target? true}\n\nThere are several functions to get information on features and inference targets:\n\n(ds-mod/feature-ecount modelled-ds)\n\n\n3\n\n\n(ds-cf/feature modelled-ds)\n\n_unnamed [3 2]:\n\n\n\n:x-1\n:x-2\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n0\n1\n\n\n\n\n(ds-cf/target modelled-ds)\n\n_unnamed [3 1]:\n\n\n\n:y\n\n\n\n\n:a\n\n\n:a\n\n\n:b",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "prepare_for_ml.html#combining-categorical-transformation-and-modelling",
    "href": "prepare_for_ml.html#combining-categorical-transformation-and-modelling",
    "title": "7  Machine learning specific functionality in tech.ml.dataset",
    "section": "7.5 Combining categorical transformation and modelling",
    "text": "7.5 Combining categorical transformation and modelling\nVery often we need to do transform and model for doing classification and combine the -&gt;numeric transformation of categorical vars and the marking of inference targets.\n\n(def ds-ready-for-train\n  (-&gt;\n   {:x-1 [0 1 0]\n    :x-2 [1 0 1]\n    :cat  [:a :b :c]\n    :y [:a :a :b]}\n\n   (ds/-&gt;dataset)\n   (ds/categorical-&gt;number [:y])\n   (ds/categorical-&gt;one-hot [:cat])\n   (ds-mod/set-inference-target [:y])))\n\n\nds-ready-for-train\n\n_unnamed [3 6]:\n\n\n\n:x-1\n:x-2\n:y\n:cat-c\n:cat-a\n:cat-b\n\n\n\n\n0\n1\n0.0\n0.0\n1.0\n0.0\n\n\n1\n0\n0.0\n0.0\n0.0\n1.0\n\n\n0\n1\n1.0\n1.0\n0.0\n0.0\n\n\n\nSuch a dataset is ready for training as it only contains numerical variables which have the categorical maps in place for easy converting back, if needed. The inference target is marked as well, as we can see in the meta data:\n\n(map meta (vals ds-ready-for-train))\n\n\n({:name :x-1, :datatype :int64, :n-elems 3}\n {:name :x-2, :datatype :int64, :n-elems 3}\n {:categorical? true,\n  :name :y,\n  :datatype :float64,\n  :n-elems 3,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :y,\n   :result-datatype :float64},\n  :inference-target? true}\n {:categorical? true,\n  :name :cat-c,\n  :datatype :float64,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}}\n {:categorical? true,\n  :name :cat-a,\n  :datatype :float64,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}}\n {:categorical? true,\n  :name :cat-b,\n  :datatype :float64,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}})\n\nMost models in the metamorph.ml ecosystem can work with data in this format.\nSide remark: If needed, data could as well be easily transformed into a tensor. Most models do this internally anyway (often to primitive arrays)\n\n(def ds-tensor\n  (tech.v3.dataset.tensor/dataset-&gt;tensor ds-ready-for-train))\n\n\nds-tensor\n\n\n#tech.v3.tensor&lt;float64&gt;[3 6]\n[[0.000 1.000 0.000 0.000 1.000 0.000]\n [1.000 0.000 0.000 0.000 0.000 1.000]\n [0.000 1.000 1.000 1.000 0.000 0.000]]\n\nor we can do so, if needed, but this looses the notation of features / inference target\n\n(tech.v3.tensor/-&gt;jvm ds-tensor)\n\n\n[[0.0 1.0 0.0 0.0 1.0 0.0]\n [1.0 0.0 0.0 0.0 0.0 1.0]\n [0.0 1.0 1.0 1.0 0.0 0.0]]\n\n\n\n\n\nsource: notebooks/prepare_for_ml.clj",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  }
]